import os
import time
from PyPDF2 import PdfReader
from dotenv import load_dotenv
from langchain_naver import ChatClovaX, ClovaXEmbeddings
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.tools.retriever import create_retriever_tool
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import MessagesState, StateGraph, END

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# 1) PDF ë¬¸ì„œ ì½ê¸°
pdf_path = "**insert document path**"
reader = PdfReader(pdf_path)

documents = []
for i, page in enumerate(reader.pages):
    text = page.extract_text()
    if text:
        documents.append(
            Document(page_content=text, metadata={"source": pdf_path, "page": i + 1})
        )

print(f"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(documents)}")

# 2) ë¬¸ì„œ ë¶„í•  (Chunking)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500, chunk_overlap=50
)
split_docs = text_splitter.split_documents(documents)
print(f"ìª¼ê°  ë¬¸ì„œ ìˆ˜: {len(split_docs)}")


# 3) í´ë¡œë°” ì„ë² ë”© ëª¨ë¸
embeddings = ClovaXEmbeddings(model="clir-emb-dolphin")

# 4) InMemory ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•
vectorstore = InMemoryVectorStore(embedding=embeddings)

batch_size = 2
for i in range(0, len(split_docs), batch_size):
    batch = split_docs[i : i + batch_size]
    vectorstore.add_documents(batch)
    print(f"{i+len(batch)}/{len(split_docs)} ì™„ë£Œ")
    time.sleep(1.0)  # RateLimit ë°©ì§€

# 5) Retriever & Tool
retriever = vectorstore.as_retriever()
retriever_tool = create_retriever_tool(
    retriever,
    name="pdf_research",
    description="ëœì„¬ì›¨ì–´ ê´€ë ¨ PDFë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” íˆ´",
)

# 6) LLM ì´ˆê¸°í™” (ClovaX)
chat = ChatClovaX(
    model="HCX-005",
    api_key=os.getenv("CLOVASTUDIO_API_KEY"),
)

# 7) ë…¸ë“œ ì •ì˜
# =====================================
# LLM ë…¸ë“œ: ì§ˆë¬¸ì„ ë°›ì•„ retriever í˜¸ì¶œ ì—¬ë¶€ íŒë‹¨
def llm_node(state: MessagesState):
    response = chat.bind_tools([retriever_tool]).invoke(state["messages"])
    return {"messages": state["messages"] + [response]}

# Retriever ì‹¤í–‰ ë…¸ë“œ
def tool_node(state: MessagesState):
    last_message = state["messages"][-1]
    tool_calls = getattr(last_message, "tool_calls", [])
    for call in tool_calls:
        if call["name"] == "pdf_research":
            docs_and_scores = vectorstore.similarity_search_with_score(
                call["args"]["query"], k=3
            )
            filtered = [doc for doc, score in docs_and_scores if score > 0.75]

            if not filtered:
                return {
                    "messages": state["messages"] + [
                        AIMessage(content="ê´€ë ¨ ë¬¸ì„œì—ì„œ ë‹µì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ì ‘ ë‹µë³€í•´ ë“œë¦´ê²Œìš”.")
                    ]
                }

            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½í•˜ë„ë¡ LLM í˜¸ì¶œ
            # ì°¸ì¡° ë‚´ìš©ì´ ë„ˆë¬´ ì»¤ì§€ë©´ í† í° ìˆ˜ê°€ ê¸‰ì¦ -> í˜„ì¬ëŠ” í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 300ìë¡œ ì œí•œ. í•„ìš” ì‹œ ëŠ˜ë ¤ë„ ë¨.
            context = "\n\n".join([doc.page_content[:300] for doc in filtered])
            prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.\n\nì§ˆë¬¸: {call['args']['query']}\n\në¬¸ì„œ ë‚´ìš©:\n{context}"
            summary = chat.invoke([HumanMessage(prompt)])

            return {"messages": state["messages"] + [summary]}

# 8. ê·¸ë˜í”„ êµ¬ì„±
graph = StateGraph(MessagesState)

graph.add_node("llm", llm_node)
graph.add_node("tool", tool_node)

graph.set_entry_point("llm")
graph.add_conditional_edges(
    "llm",
    lambda state: "tool"
    if getattr(state["messages"][-1], "tool_calls", None)
    else END,
    {"tool": "tool", END: END},
)
graph.add_edge("tool", END)

app = graph.compile()

# ì‹¤í–‰ ë£¨í”„
while True:
    content = input("âœ… ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” : ")
    if content.lower() == "q":
        break

    input_state = {"messages": [HumanMessage(content)]}
    final_state = app.invoke(input_state)

    # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ë§Œ ì¶œë ¥
    last_ai_msg = None
    for m in final_state["messages"]:
        if m.type == "ai":
            last_ai_msg = m

    if last_ai_msg:
        print("\nğŸ“Œ ë‹µë³€:\n", last_ai_msg.content.strip(), "\n")